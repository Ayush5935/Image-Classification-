{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification using Deep learning and neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path = 'Fruits_Vegetables\\train'\n",
    "data_test_path = 'Fruits_Vegetables\\test'\n",
    "data_val_path = 'Fruits_Vegetables\\validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting our images in same size , like each images may have different size so its important to set image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 180\n",
    "img_height = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data set is in form of images and images is in the folders ,  so we have to bring the data set in the form of arrays (Using functionaity which is provide by tensor flow is load from disks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = tf.keras.utils.image_dataset_from_directory(data_train_path, #path of dataset\n",
    "                                                         shuffle = True, #for suffeling my dataset \n",
    "                                                         image_size=(img_width,img_height), # to size image to 180 \n",
    "                                                         batch_size=32, # size of batch \n",
    "                                                         validation_split= False) #if we have one datase it will split dataset into two parts test and val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what type of fruits and vegitables we have in our dataset i.e different classes for classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now loading all dataset classes into one , i.e data_categoies\n",
    "data_cat = data_train.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have done laoding of dataset from disk to array for train dataset , lets do it for valiadation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = tf.keras.utils.image_dataset_from_directory(data_val_path,\n",
    "                                                         shuffle = False,\n",
    "                                                         image_size=(img_width,img_height),\n",
    "                                                         batch_size=32,\n",
    "                                                         validation_split= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = tf.keras.utils.image_dataset_from_directory(data_test_path,\n",
    "                                                         shuffle = False,\n",
    "                                                         image_size=(img_width,img_height),\n",
    "                                                         batch_size=32,\n",
    "                                                         validation_split= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Printing some images from training dataset along with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for image , labels in data_train.take(1):\n",
    "    for i in range(9):\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(image[i].numpy().astype('uint8'))\n",
    "        plt.title(data_cat[labels[i]])\n",
    "       # plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creatin seq model\n",
    "model = Sequential(\n",
    "    layers.Rescaling(1./255), #for Storing Clour in RBG so diving by 255\n",
    "    layers.Conv2D( 16,3, padding='same',activation='relu'),  # 16 units neurons \n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32,3,padding='same',activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(64,3,padding='same',activaton='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flattern(),\n",
    "    layers.Dropout(0,2),\n",
    "    layers.Dense(128),\n",
    "    layers.Dense(len(data_cat))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are compling our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam' , loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_size = 25\n",
    "history = model.fit(data_train, validation_data= data_val, epochs = epochs_size, batch_size=32, verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Drawing Charts between traning data set v/s validation datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(epochs_size)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range,history.history['accuracy'],label = 'Training Accuracy')\n",
    "plt.plot(epochs_range,history.history['val_accuracy'],label = 'Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range,history.history['loss'],label = 'Training loss')\n",
    "plt.plot(epochs_range,history.history['val_loss'],label = 'Validation loss')\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now give your own image in file side \n",
    "\n",
    "image ='Apple.jpeg'\n",
    "image = tf.keras.utils.load_img(image,target_size=(img_height,img_width))\n",
    "img_arr = tf.keras.utils.array_to_img(image)\n",
    "img_bat = tf.expand_dims(img_arr,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now predict \n",
    "\n",
    "predict = model.predict(img_bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now find the score \n",
    "\n",
    "score = tf.nn.softmax(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('veg/fruit in image is {} with accuracy of {:0.2f}'.format(data_cat[np.argmax(score)],np.max(score)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now creating our web application \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Image_classify.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Moving to VS code for creating web application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
